{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sib_ldsc_z' from '/disk/homedirs/nber/harij/gitrepos/SNIPar/ldsc_reg/sib_ldsc_z.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sib_ldsc_z as ld\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import comb\n",
    "from scipy.misc import derivative\n",
    "import scipy.stats\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import datetime\n",
    "import multiprocessing\n",
    "# import numdifftools as nd\n",
    "reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning there is no value for z. Maybe consider simulating it\n",
      "No value for U given. Generating a vector of ones (all SNPs weighted equally)\n",
      "No value for LD Scores given. Generating a vector of ones for l\n",
      "Warning: No value given for allele frequencies. Some parameters won't be normalized.\n",
      "No value for effective number of loci is given. Using total number of loci instead\n",
      "Simulated LD scores!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "N = int(1e4)\n",
    "S = np.array([[[1., -0.5], [-0.5, 1.]]] * N)/N\n",
    "V = np.array([[0.5, 0.25], [0.25, 0.5]])\n",
    "\n",
    "model = ld.sibreg(S = S)\n",
    "model.simdata(V/N, N, simld = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No initial guess provided.\n",
      "Making Method of Moments Guess\n",
      "Initial estimate: [1.55430175 1.47910632 0.53409088]\n",
      "Wall time: 12.4 s\n",
      "      fun: 37189.05234762325\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-0.02739723, -0.02879562, -0.00672324])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 11\n",
      "      nit: 8\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([0.51801607, 0.49264674, 0.53215414])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hariharan\\Documents\\git_repos\\SNIPar\\ldsc_reg\\sib_ldsc_z.py:556: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std_err_mat = np.sqrt(invH)\n"
     ]
    }
   ],
   "source": [
    "# solving\n",
    "%time output, result = model.solve()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v1': 0.5180160703428223,\n",
       " 'v2': 0.4926467370660001,\n",
       " 'r': 0.5321541425848505,\n",
       " 'std_err_mat': array([[0.01221355, 0.00124924,        nan],\n",
       "        [0.00124924, 0.01186258,        nan],\n",
       "        [       nan,        nan, 0.01696686]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring how data is sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_17.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_5.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_1.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_13.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_22.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_9.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_8.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_16.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_4.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_12.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_18.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_14.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_6.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_2.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_10.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_21.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_15.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_7.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_3.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_11.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_20.hdf5\n",
      "Reading in file:  /disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_19.hdf5\n",
      "Number of Observations before merging LD-Scores, before removing low MAF SNPs: 147403\n",
      "Number of Observations before merging LD-Scores, after removing low MAF SNPs: 147403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "filenames = \"/disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/phenotype_dir_par_corr_0.5/1/chr_*.hdf5\"\n",
    "files = glob.glob(filenames)\n",
    "\n",
    "file = files[0]\n",
    "print(\"Reading in file: \", file)\n",
    "hf = h5py.File(file, 'r')\n",
    "metadata = hf.get(\"bim\")[()]\n",
    "chromosome = metadata[:, 0]\n",
    "snp = metadata[:, 1]\n",
    "bp = metadata[:, 3]\n",
    "theta  = hf.get('estimate')[()]\n",
    "se  = hf.get('estimate_ses')[()]\n",
    "N = hf.get('N_L')[()]\n",
    "S = hf.get('estimate_covariance')[()]\n",
    "f = hf.get('freqs')[()]\n",
    "\n",
    "# normalizing S\n",
    "sigma2 = hf.get('sigma2')[()]\n",
    "tau = hf.get('tau')[()]\n",
    "phvar = sigma2+sigma2/tau\n",
    "\n",
    "if len(files) > 1:\n",
    "    for file in files[1:]:\n",
    "        print(\"Reading in file: \", file)\n",
    "        hf = h5py.File(file, 'r')\n",
    "        metadata = hf.get(\"bim\")[()]\n",
    "        chromosome_file = metadata[:, 0]  \n",
    "        snp_file = metadata[:, 1]\n",
    "        bp_file = metadata[:, 3]\n",
    "        theta_file  = hf.get('estimate')[()]\n",
    "        se_file  = hf.get('estimate_ses')[()]\n",
    "        S_file = hf.get('estimate_covariance')[()]\n",
    "        f_file = hf.get('freqs')[()]\n",
    "        N_file = hf.get('N_L')[()]\n",
    "\n",
    "        # normalizing S\n",
    "        sigma2 = hf.get('sigma2')[()]\n",
    "        tau = hf.get('tau')[()]\n",
    "\n",
    "        chromosome = np.append(chromosome, chromosome_file, axis = 0)\n",
    "        snp = np.append(snp, snp_file, axis = 0)\n",
    "        bp = np.append(bp, bp_file, axis = 0)\n",
    "        theta = np.append(theta, theta_file, axis = 0)\n",
    "        se = np.append(se, se_file, axis = 0)\n",
    "        S = np.append(S, S_file, axis = 0)\n",
    "        f = np.append(f, f_file, axis = 0)\n",
    "        N = np.append(N, N_file, axis = 0)\n",
    "\n",
    "# Constructing dataframe of data\n",
    "zdata = pd.DataFrame({'CHR' : chromosome,\n",
    "                    'SNP' : snp,\n",
    "                    'BP' : bp,\n",
    "                    'N' : N,\n",
    "                    \"f\" : f,\n",
    "                    'theta' : theta.tolist(),\n",
    "                    'se' : se.tolist(),\n",
    "                    \"S\" : S.tolist()})\n",
    "\n",
    "\n",
    "# cleaning up a bit\n",
    "zdata['CHR'] = zdata['CHR'].astype(int)\n",
    "zdata['SNP'] = zdata['SNP'].astype(str).str.replace(\"b'\", \"\").str[:-1]\n",
    "zdata['BP'] = zdata['BP'].astype(str).str.replace(\"b'\", \"\").str[:-1]\n",
    "zdata['BP'] = zdata['BP'].astype('int')\n",
    "\n",
    "# sorting by chromosome\n",
    "zdata = zdata.sort_values(by = ['CHR']).reset_index(drop = True)\n",
    "zdata['ordering'] = zdata.index\n",
    "\n",
    "\n",
    "zdata_n_message = f\"Number of Observations before merging LD-Scores, before removing low MAF SNPs: {zdata.shape[0]}\"\n",
    "\n",
    "print(zdata_n_message)\n",
    "\n",
    "# dropping obs based on MAF\n",
    "# zdata = zdata[zdata['f'] >= args.maf/100.0]\n",
    "\n",
    "zdata_n_message = f\"Number of Observations before merging LD-Scores, after removing low MAF SNPs: {zdata.shape[0]}\"\n",
    "\n",
    "print(zdata_n_message)\n",
    "\n",
    "# == Reading in LD Scores == #\n",
    "ldscore_path = \"/disk/genetics/ukb/alextisyoung/haplotypes/simulated_pops_large/from_chr1_to_chr23_start0_endNone_run0_p0-0_ab_corr0-5_vb0-25_length2/ldscores/*[0-9].l2.ldscore.gz\"\n",
    "ldcolnames = [\"CHR\", \"SNP\", \"BP\", \"L2\"]\n",
    "ldscores= ld.read_ldscores(ldscore_path, ldcolnames)\n",
    "# ldscores['BP'] = ldscores['BP'].astype('int')\n",
    "\n",
    "# Merging LD scores with main Data Frame\n",
    "main_df = zdata.merge(ldscores, how = \"inner\", on = [\"CHR\", \"SNP\"])\n",
    "main_df = main_df.sort_values(by = ['ordering'])\n",
    "\n",
    "# dropping NAs\n",
    "main_df = main_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring JKSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n",
      "Initial estimate: [0.51801607 0.49264674 0.53215414]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "\n",
    "blocksize = 100\n",
    "nblocks = int(np.ceil(model.z.shape[0]/blocksize))\n",
    "indices = list(range(model.z.shape[0]))\n",
    "index_blocks = [indices[i * blocksize:(i + 1) * blocksize] for i in range((len(indices) + blocksize - 1) // blocksize )]\n",
    "\n",
    "full_est = np.array([output['v1'], output['v2'], output['r']])\n",
    "\n",
    "jkse_toparallelize = partial(ld.jkse_core, model = model, full_est = full_est, rbounds = True)\n",
    "\n",
    "num_procs = 4\n",
    "pool = mp.Pool(num_procs)\n",
    "estimates_jk = pool.map(jkse_toparallelize, index_blocks)\n",
    "estimates_jk = np.array(estimates_jk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01234442, 0.01156068, 0.01806745])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.jkse(model, output, blocksize = 100, num_procs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate JKSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_shape(x, y):\n",
    "    '''Check that x and y have the correct shapes (for regression jackknives).'''\n",
    "    if len(x.shape) != 2 or len(y.shape) != 2:\n",
    "        raise ValueError('x and y must be 2D arrays.')\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\n",
    "            'Number of datapoints in x != number of datapoints in y.')\n",
    "    if y.shape[1] != 1:\n",
    "        raise ValueError('y must have shape (n_snp, 1)')\n",
    "    n, p = x.shape\n",
    "    if p > n:\n",
    "        raise ValueError('More dimensions than datapoints.')\n",
    "\n",
    "    return (n, p)\n",
    "\n",
    "class Jackknife():\n",
    "\n",
    "    '''\n",
    "    Base class for jackknife objects. Input involves x,y, so this base class is tailored\n",
    "    for statistics computed from independent and dependent variables (e.g., regressions).\n",
    "    The __delete_vals_to_pseudovalues__ and __jknife__ methods will still be useful for other\n",
    "    sorts of statistics, but the __init__ method will need to be overriden.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.matrix with shape (n, p)\n",
    "        Independent variable.\n",
    "    y : np.matrix with shape (n, 1)\n",
    "        Dependent variable.\n",
    "    n_blocks : int\n",
    "        Number of jackknife blocks\n",
    "    *args, **kwargs :\n",
    "        Arguments for inheriting jackknives.\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_blocks : int\n",
    "        Number of jackknife blocks\n",
    "    p : int\n",
    "        Dimensionality of the independent varianble\n",
    "    N : int\n",
    "        Number of datapoints (equal to x.shape[0])\n",
    "    Methods\n",
    "    -------\n",
    "    jknife(pseudovalues):\n",
    "        Computes jackknife estimate and variance from the jackknife pseudovalues.\n",
    "    delete_vals_to_pseudovalues(delete_vals, est):\n",
    "        Converts delete values and the whole-data estimate to pseudovalues.\n",
    "    get_separators():\n",
    "        Returns (approximately) evenly-spaced jackknife block boundaries.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, n_blocks=None, separators=None):\n",
    "        self.N, self.p = model.z.shape\n",
    "        if separators is not None:\n",
    "            if max(separators) != self.N:\n",
    "                raise ValueError(\n",
    "                    'Max(separators) must be equal to number of data points.')\n",
    "            if min(separators) != 0:\n",
    "                raise ValueError('Max(separators) must be equal to 0.')\n",
    "            self.separators = sorted(separators)\n",
    "            self.n_blocks = len(separators) - 1\n",
    "        elif n_blocks is not None:\n",
    "            self.n_blocks = n_blocks\n",
    "            self.separators = self.get_separators(self.N, self.n_blocks)\n",
    "        else:\n",
    "            raise ValueError('Must specify either n_blocks are separators.')\n",
    "\n",
    "        if self.n_blocks > self.N:\n",
    "            raise ValueError('More blocks than data points.')\n",
    "\n",
    "    @classmethod\n",
    "    def jknife(cls, pseudovalues):\n",
    "        '''\n",
    "        Converts pseudovalues to jackknife estimate and variance.\n",
    "        Parameters\n",
    "        ----------\n",
    "        pseudovalues : np.matrix pf floats with shape (n_blocks, p)\n",
    "        Returns\n",
    "        -------\n",
    "        jknife_est : np.matrix with shape (1, p)\n",
    "            Jackknifed estimate.\n",
    "        jknife_var : np.matrix with shape (1, p)\n",
    "            Variance of jackknifed estimate.\n",
    "        jknife_se : np.matrix with shape (1, p)\n",
    "            Standard error of jackknifed estimate, equal to sqrt(jknife_var).\n",
    "        jknife_cov : np.matrix with shape (p, p)\n",
    "            Covariance matrix of jackknifed estimate.\n",
    "        '''\n",
    "        n_blocks = pseudovalues.shape[0]\n",
    "        jknife_cov = np.atleast_2d(np.cov(pseudovalues.T, ddof=1) / n_blocks)\n",
    "        jknife_var = np.atleast_2d(np.diag(jknife_cov))\n",
    "        jknife_se = np.atleast_2d(np.sqrt(jknife_var))\n",
    "        jknife_est = np.atleast_2d(np.mean(pseudovalues, axis=0))\n",
    "        return (jknife_est, jknife_var, jknife_se, jknife_cov)\n",
    "\n",
    "    @classmethod\n",
    "    def delete_values_to_pseudovalues(cls, delete_values, est):\n",
    "        '''\n",
    "        Converts whole-data estimate and delete values to pseudovalues.\n",
    "        Parameters\n",
    "        ----------\n",
    "        delete_values : np.matrix with shape (n_blocks, p)\n",
    "            Delete values.\n",
    "        est : np.matrix with shape (1, p):\n",
    "            Whole-data estimate.\n",
    "        Returns\n",
    "        -------\n",
    "        pseudovalues : np.matrix with shape (n_blocks, p)\n",
    "            Psuedovalues.\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError :\n",
    "            If est.shape != (1, delete_values.shape[1])\n",
    "        '''\n",
    "        n_blocks, p = delete_values.shape\n",
    "        if est.shape != (1, p):\n",
    "            raise ValueError(\n",
    "                'Different number of parameters in delete_values than in est.')\n",
    "\n",
    "        return n_blocks * est - (n_blocks - 1) * delete_values\n",
    "\n",
    "    @classmethod\n",
    "    def get_separators(cls, N, n_blocks):\n",
    "        '''Define evenly-spaced block boundaries.'''\n",
    "        return np.floor(np.linspace(0, N, n_blocks + 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstsqJackknifeSlow():\n",
    "\n",
    "    '''\n",
    "    Slow linear-regression block jackknife. This class computes delete values directly,\n",
    "    rather than forming delete values from block values. Useful for testing and for\n",
    "    non-negative least squares (which as far as I am aware does not admit a fast block\n",
    "    jackknife algorithm).\n",
    "    Inherits from Jackknife class.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.matrix with shape (n, p)\n",
    "        Independent variable.\n",
    "    y : np.matrix with shape (n, 1)\n",
    "        Dependent variable.\n",
    "    n_blocks : int\n",
    "        Number of jackknife blocks\n",
    "    nn: bool\n",
    "        Non-negative least-squares?\n",
    "    Attributes\n",
    "    ----------\n",
    "    est : np.matrix with shape (1, p)\n",
    "        FWLS estimate.\n",
    "    jknife_est : np.matrix with shape (1, p)\n",
    "        Jackknifed estimate.\n",
    "    jknife_var : np.matrix with shape (1, p)\n",
    "        Variance of jackknifed estimate.\n",
    "    jknife_se : np.matrix with shape (1, p)\n",
    "        Standard error of jackknifed estimate, equal to sqrt(jknife_var).\n",
    "    jknife_cov : np.matrix with shape (p, p)\n",
    "        Covariance matrix of jackknifed estimate.\n",
    "    delete_vals : np.matrix with shape (n_blocks, p)\n",
    "        Jackknife delete values.\n",
    "    Methods\n",
    "    -------\n",
    "    delete_values(x, y, func, s):\n",
    "        Compute delete values of func(x, y) the slow way, with blocks defined by s.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, rbounds=True, n_blocks=None, separators=None):\n",
    "        \n",
    "        mdl = Jackknife(model, n_blocks, separators)\n",
    "        \n",
    "        self.rbounds = rbounds\n",
    "\n",
    "        func = model.solve\n",
    "        self.est = np.atleast_2d(np.array([model.output['v1'], model.output['v2'],\n",
    "                            model.output['r']]))\n",
    "        self.s = mdl.separators\n",
    "        self.delete_values = self.delete_values(model, func, mdl.separators)\n",
    "        self.pseudovalues = mdl.delete_values_to_pseudovalues(\n",
    "            self.delete_values, self.est)\n",
    "        (self.jknife_est, self.jknife_var, self.jknife_se, self.jknife_cov) =\\\n",
    "            mdl.jknife(self.pseudovalues)\n",
    "        \n",
    "        \n",
    "    def delete_values(self, model, func, s):\n",
    "        '''\n",
    "        Compute delete values by deleting one block at a time.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.matrix with shape (n, p)\n",
    "            Independent variable.\n",
    "        y : np.matrix with shape (n, 1)\n",
    "            Dependent variable.\n",
    "        func : function (n, p) , (n, 1) --> (1, p)\n",
    "            Function of x and y to be jackknived.\n",
    "        s : list of ints\n",
    "            Block separators.\n",
    "        Returns\n",
    "        -------\n",
    "        delete_values : np.matrix with shape (n_blocks, p)\n",
    "            Delete block values (with n_blocks blocks defined by parameter s).\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError :\n",
    "            If x.shape[0] does not equal y.shape[0] or x and y are not 2D.\n",
    "        '''\n",
    "        \n",
    "        d = []\n",
    "        for i in range(len(s) - 1):\n",
    "            d_in = func(z = np.vstack([model.z[0:s[i], ...], model.z[s[i + 1]:, ...]]), \n",
    "                      S = np.vstack([model.S[0:s[i], ...], model.S[s[i + 1]:, ...]]),\n",
    "                      l = np.hstack([model.l[0:s[i], ...], model.l[s[i + 1]:, ...]]),\n",
    "                      u = np.hstack([model.u[0:s[i], ...], model.u[s[i + 1]:, ...]]),\n",
    "                      f = model.f,\n",
    "                      M = model.M,\n",
    "                    printout = False,\n",
    "                    est_init = self.est,\n",
    "                    rbounds = self.rbounds)[0]\n",
    "            dmat = np.array([d_in['v1'], d_in['v2'], d_in['r']])\n",
    "            \n",
    "            d.append(dmat)\n",
    "\n",
    "        return np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n",
      "Initial estimate: [[0.52373377 0.48447394 0.54189711]]\n"
     ]
    }
   ],
   "source": [
    "ldsc_jk = LstsqJackknifeSlow(model, n_blocks=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDSC implementation and our implementation of block jackknife seem to yield the same answers (there are very small differences due to each run's estimate being slightly different due to randomization. You can check this by running model.solve on the same data twice and it won't be exactly the same answer).\n",
    "\n",
    "So sanity check, our block jackknife implementation is fine for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
