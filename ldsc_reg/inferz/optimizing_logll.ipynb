{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'sib_ldsc_z' from 'c:\\\\Users\\\\Hariharan\\\\Documents\\\\git_repos\\\\SNIPar\\\\ldsc_reg\\\\inferz\\\\sib_ldsc_z.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sib_ldsc_z as ld\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import comb\n",
    "from scipy.misc import derivative\n",
    "import scipy.stats\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import glob\n",
    "import numba\n",
    "from numba import jit, njit, prange\n",
    "reload(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "N = int(1e4)\n",
    "S = np.array([[[1e-4, -5 * 1e-5], [-5 * 1e-5, 1e-4]]] * N)\n",
    "V = np.array([[0.5, 0.25], [0.25, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base functions\n",
    "def extract_upper_triangle(x):\n",
    "    \n",
    "    # =============================== #\n",
    "    # Extracts the upper triangular portion of \n",
    "    # a symmetric matrix\n",
    "    # =============================== #\n",
    "    \n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    \n",
    "    upper_triangle = x[np.triu_indices(n)]\n",
    "    \n",
    "    return upper_triangle\n",
    "\n",
    "def return_to_symmetric(triangle_vec, final_size):\n",
    "    \n",
    "    # =============================== #\n",
    "    # Given a vector of the upper triangular matrix,\n",
    "    # get back the symmetric matrix\n",
    "    # =============================== #\n",
    "    \n",
    "    X = np.zeros((final_size,final_size))\n",
    "    X[np.triu_indices(X.shape[0], k = 0)] = triangle_vec\n",
    "    X = X + X.T - np.diag(np.diag(X))\n",
    "    \n",
    "    return X\n",
    "\n",
    "def extract_bounds(n):\n",
    "    \n",
    "    # =============================== #\n",
    "    # From a number n, the function\n",
    "    # outputs a list of bounds\n",
    "    # for a var cov matrix of size\n",
    "    # n x n\n",
    "    # =============================== #\n",
    "    \n",
    "    # extract idx of flat array whcih are diagonals\n",
    "    uptriangl_idx = np.array(np.triu_indices(n))\n",
    "    diags = uptriangl_idx[0, :] == uptriangl_idx[1, :]\n",
    "    \n",
    "    # Construct list of bounds\n",
    "    bounds_list = np.array([(None, None)] * len(diags))\n",
    "    bounds_list[diags] = (1e-6, None)\n",
    "    \n",
    "    bounds_list_out = [tuple(i) for i in bounds_list]\n",
    "    \n",
    "    return bounds_list_out\n",
    "\n",
    "\n",
    "def delete_obs_jk(var, start_idx, end_idx, end_cond):\n",
    "\n",
    "    # ============================== #\n",
    "    # var: numpy array\n",
    "    # end_cond : boolean\n",
    "    # Function helps take out observations\n",
    "    # for a jackknife routine\n",
    "    # ============================== #\n",
    "\n",
    "    if end_cond:\n",
    "\n",
    "        var_jk = np.delete(var, range(start_idx, end_idx), \n",
    "                             axis = 0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        var_jk = np.delete(var, range(start_idx, var.shape[0]), \n",
    "                             axis = 0)\n",
    "        var_jk = np.delete(var_jk, range(end_idx - var.shape[0]))\n",
    "        \n",
    "    return var_jk\n",
    "\n",
    "\n",
    "@njit\n",
    "def normalize_S(S, norm):\n",
    "    '''\n",
    "    A function which normalizes a vector of S matrices\n",
    "    '''\n",
    "    \n",
    "    N = S.shape[0]\n",
    "    S_norm = np.zeros_like(S)\n",
    "    for idx in range(N):\n",
    "        \n",
    "        Si = S[idx]\n",
    "        normi = norm[idx]\n",
    "        S_norm[idx] = Si * normi\n",
    "    \n",
    "    return S_norm\n",
    "\n",
    "@njit\n",
    "def calc_inv_root(S):\n",
    "    '''\n",
    "    A stable solver for S^{-1/2}\n",
    "    '''\n",
    "    \n",
    "    if ~np.any(np.isnan(S)):\n",
    "        S_eig = np.linalg.eig(S)\n",
    "        l = np.zeros(S.shape)\n",
    "        np.fill_diagonal(l,np.power(S_eig[0],-0.5))\n",
    "        S_inv_root = S_eig[1].dot(np.dot(l,S_eig[1].T))\n",
    "    else:\n",
    "        S_inv_root =  np.empty_like(S)\n",
    "        S_inv_root[:] = np.nan\n",
    "    return S_inv_root\n",
    "\n",
    "    \n",
    "@njit\n",
    "def standardize_mat(V, S, M):\n",
    "    '''\n",
    "    Standardizes V and S matrices by constructing\n",
    "    D = M [[1/sigma_1, 0], [0, 1/sigma_2]]. sigma_1 and sigma_2\n",
    "    come from the S matrix provided.\n",
    "    \n",
    "    Then Vnew = Dmat @ V @ Dmat\n",
    "    and Snew = Dmat @ S @ Dmat\n",
    "    '''\n",
    "    \n",
    "    sigma1 = np.sqrt(M * S[0, 0])\n",
    "    sigma2 = np.sqrt(M * S[1, 1])\n",
    "    \n",
    "    Dmat = np.sqrt(M) * np.array([[1/sigma1, 0], \n",
    "                                [0, 1/sigma2]])\n",
    "    Snew = Dmat @ S @ Dmat\n",
    "    Vnew = Dmat @ V @ Dmat\n",
    "    \n",
    "    return Vnew, Snew\n",
    "\n",
    "@njit\n",
    "def V2Vmat(V, M):\n",
    "    '''\n",
    "    Transforms a 1 dimensional V array\n",
    "    with 3 elements v1, v2 and r\n",
    "    into a V matrix\n",
    "    '''\n",
    "    # getting important scalars\n",
    "    v1 = V[0]\n",
    "    v2 = V[1]\n",
    "    r = V[2]\n",
    "\n",
    "    Vmat = (1/M) * np.array([[v1, r * np.sqrt(v1 * v2)], [r * np.sqrt(v1 * v2), v2]])\n",
    "\n",
    "    return Vmat\n",
    "\n",
    "@njit \n",
    "def Vmat2V(Vmat, M):\n",
    "    '''\n",
    "    Makes a 2x2 V matrix\n",
    "    into a 1 dimensional V\n",
    "    array containing v1, v2 and\n",
    "    r\n",
    "    '''\n",
    "\n",
    "    v1 = M * Vmat[0, 0]\n",
    "    v2 = M * Vmat[1, 1]\n",
    "    r = M * Vmat[0, 1]/np.sqrt(v1 * v2)\n",
    "    r_check = M * Vmat[1, 0]/np.sqrt(v1 * v2)\n",
    "\n",
    "    assert r == r_check\n",
    "\n",
    "    return np.array([v1, v2, r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simdata(V, S, N, simr = False):\n",
    "    \"\"\"\n",
    "    Simulates data for z scores.\n",
    "    \n",
    "    Inputs:\n",
    "    V = varcov matrix of true effects\n",
    "    N = Number of obs/SNPs to generate\n",
    "    simr = boolean indicating if we want\n",
    "            to simulate ldscores\n",
    "            \n",
    "    \n",
    "    Outputs:\n",
    "    None\n",
    "    \n",
    "    - It creates an object within the class\n",
    "    called z\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    zhat_vec = np.empty((N, V.shape[1]))\n",
    "    for i in range(N):\n",
    "        \n",
    "        Si = S[i]\n",
    "        \n",
    "        V = np.array(V)\n",
    "        Si = np.array(Si)\n",
    "\n",
    "        # get shape of V\n",
    "        d = V.shape[0]\n",
    "        zeromat = np.zeros(d)\n",
    "        Vnew, Snew = standardize_mat(V, Si, N)\n",
    "\n",
    "        # generate true effect vector\n",
    "        sim = np.random.multivariate_normal(zeromat, Snew + Vnew)\n",
    "        \n",
    "        # Append to vector of effects\n",
    "        zhat_vec[i, :] = sim\n",
    "\n",
    "    return zhat_vec\n",
    "\n",
    "z = simdata(V/N, S, N)\n",
    "r = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logll_scipy(V, z, S, r, N):\n",
    "\n",
    "    '''\n",
    "    Gets log likelihood function from scipy\n",
    "    Used to test if our log likelihood function \n",
    "    is defined correctly\n",
    "    '''\n",
    "\n",
    "    Vmat = V2Vmat(V, N)\n",
    "    \n",
    "    Vnew, Snew = standardize_mat(Vmat, S, N)\n",
    "\n",
    "    dist = scipy.stats.multivariate_normal(mean = None,\n",
    "                                          cov = Vnew + Snew)\n",
    "\n",
    "    nlogll = dist.logpdf(z)\n",
    "    return nlogll\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-3.3159026093560375"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "get_logll_scipy(Vmat2V(V/N, N), z[0, :], S[0], r[0], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _log_ll(V, z, S, r, N):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the log likelihood matrix for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        l_i = -\\frac{d}{2} log (2 \\pi) - \\frac{1}{2} log ( |I + r_i S_i^{-1/2} V S_i^{-1/2}| ) -\n",
    "                \\frac{1}{2} z_i^T (I + r_i S_i^{-1/2} V S_i^{-1/2}) ^{-1} z_i\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dx1 numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    r = scalar\n",
    "    f = scalar\n",
    "\n",
    "    Outputs:\n",
    "    logll = scalar\n",
    "    \"\"\"\n",
    "    Vmat = V2Vmat(V, N)\n",
    "\n",
    "    Vnew, Snew = standardize_mat(Vmat, S, N)\n",
    "    Sigma = Snew + Vnew\n",
    "    logdet = np.linalg.slogdet(Sigma)\n",
    "\n",
    "    det = np.linalg.det(Sigma)\n",
    "    if det > 1e-6 or det < -1e-6:\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "    else:\n",
    "        Sigma_inv = np.linalg.pinv(Sigma)\n",
    "\n",
    "    d = Vmat.shape[0]\n",
    "    z = z.reshape(d,1)\n",
    "\n",
    "    L = - (d/2) * np.log(2 * np.pi) \\\n",
    "        - (1/2) * logdet[0]*logdet[1] \\\n",
    "        - (1/2) * z.T @ Sigma_inv @ z\n",
    "\n",
    "    return L[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-3.315902609356038"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "_log_ll(Vmat2V(V/N, N), z[0, :], S[0], r[0], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log likelihood seems to be correctly defined\n"
     ]
    }
   ],
   "source": [
    "boolcond = np.allclose(get_logll_scipy(Vmat2V(V/N, N), z[0, :], S[0], r[0], N), _log_ll(Vmat2V(V/N, N), z[0, :], S[0], r[0], N))\n",
    "\n",
    "print(\"Log likelihood seems to be correctly defined\") if boolcond else print(\"Log likelihood isn't correctly defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _grad_ll_v(V, z, S, r, N):\n",
    "\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    Vmat = V2Vmat(V, N)\n",
    "    d = S.shape[0]\n",
    "\n",
    "    Vnew, Snew = standardize_mat(Vmat, S, N)\n",
    "    Sigma = Snew + Vnew\n",
    "    \n",
    "    # getting important scalars\n",
    "    v1 = V[0]\n",
    "    v2 = V[1]\n",
    "    r = V[2]\n",
    "\n",
    "    rs = Snew[0, 1]\n",
    "\n",
    "    sigma1 = np.sqrt(N * S[0, 0])\n",
    "    sigma2 = np.sqrt(N * S[1, 1])\n",
    "\n",
    "    sigma1sq = sigma1 ** 2\n",
    "    sigma2sq = sigma2 ** 2\n",
    "    \n",
    "    assert len(z.shape) == 1\n",
    "    \n",
    "    z1 = z[0]\n",
    "    z2 = z[1]\n",
    "    \n",
    "    z1sq = z1 ** 2\n",
    "    z2sq = z2 ** 2\n",
    "\n",
    "    det = np.linalg.det(Sigma)\n",
    "\n",
    "    T = z1sq * (1 + (v2/sigma2sq)) - \\\n",
    "            2 * z1 * z2 * (rs + r * np.sqrt(v1 * v2)/(sigma1 * sigma2)) + \\\n",
    "            z2sq * (1 + v1/sigma1sq)\n",
    "\n",
    "    # gradient wrt v1\n",
    "    ddet_dv1 = 1/sigma1sq * (1 + v2/sigma2sq) - (r/(sigma1 * sigma2)) * \\\n",
    "            (rs * np.sqrt(v2/v1) + r * v2/(sigma1 * sigma2)) \n",
    "\n",
    "    dT_dv1 = (z2sq/sigma1sq) - (r * z1 * z2)/(sigma1 * sigma2) * np.sqrt(v2/v1)\n",
    "\n",
    "    dl_dv1 = -(1/2) * 1/det * (ddet_dv1 * (1 - T/det) + dT_dv1)\n",
    "\n",
    "    # gradient wrt v2\n",
    "    ddet_dv2 = 1/sigma2sq * (1 + v1/sigma1sq) - (r/(sigma1 * sigma2)) * \\\n",
    "            (rs * np.sqrt(v1/v2) + r * v1/(sigma1 * sigma2)) \n",
    "\n",
    "    dT_dv2 = (z1sq/sigma2sq) - (r * z1 * z2)/(sigma1 * sigma2) * np.sqrt(v1/v2)\n",
    "\n",
    "    dl_dv2 = -(1/2) * 1/det * (ddet_dv2 * (1 - T/det) + dT_dv2)\n",
    "\n",
    "    # gradient wrt r\n",
    "    ddet_dr = -2 * np.sqrt(v1 * v2)/(sigma1 * sigma2) * \\\n",
    "         (rs + (r * np.sqrt(v1 * v2))/(sigma1 * sigma2))\n",
    "\n",
    "    dT_dr = -2 * np.sqrt(v1 * v2)/(sigma1 * sigma2) * z1 * z2\n",
    "\n",
    "    dl_dr = -(1/2) * 1/det * (ddet_dr * (1 - T/det) + dT_dr)\n",
    "\n",
    "    return np.array([dl_dv1, dl_dv2, dl_dr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.37720196, -0.3548698 , -0.02657381])"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "_grad_ll_v(Vmat2V(V/N, N), z[0, :], S[0], r[0], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _num_grad_V(V, z, S, r, N):\n",
    "    \"\"\"\n",
    "    Returns numerical gradient vector of self._log_ll\n",
    "    Mostly meant to check if self._grad_ll_v is working\n",
    "    properly\n",
    "        \n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dx1 numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "        \n",
    "    Outputs:\n",
    "    g = dxd matrix \n",
    "    \"\"\"\n",
    "    \n",
    "    g = np.zeros(V.shape)\n",
    "\n",
    "    for i in range(0,V.shape[0]):\n",
    "        dV = np.zeros(V.shape)\n",
    "        dV[i] = 10 ** (-6)\n",
    "        V_upper = V+dV\n",
    "        V_lower = V-dV\n",
    "        g[i] = (_log_ll(V_upper, z, S, r, N) - \\\n",
    "                    _log_ll(V_lower, z, S, r, N)) / (2 * 10 ** (-6))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.37720196, -0.3548698 , -0.02657381])"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "_num_grad_V(Vmat2V(V/N, N), z[0, :], S[0], r[0], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "np.allclose(_num_grad_V(Vmat2V(V/N, N), z[0, :], S[0], r[0], N),\n",
    "            _grad_ll_v(Vmat2V(V/N, N), z[0, :], S[0], r[0], N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def neg_logll_grad(V, \n",
    "                   z, S, \n",
    "                   u, r):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the loglikelihood and its gradient wrt V for a given SNP i as formulated by:\n",
    "\n",
    "    .. math::\n",
    "        l_i = -\\frac{d}{2} log (2 \\pi) - \\frac{1}{2} log ( |I + r_i S_i^{-1/2} V S_i^{-1/2}| ) -\n",
    "                \\frac{1}{2} z_i^T (I + r_i S_i^{-1/2} V S_i^{-1/2}) ^{-1} z_i\n",
    "\n",
    "    and\n",
    "\n",
    "    .. math::\n",
    "        \\frac{dl}{dV} = S^{-1/2} \\Sigma_i^{-1} (\\Sigma - z_i z_i^T) \\Sigma_i^{-1} S^{-1/2}\n",
    "\n",
    "    Inputs:\n",
    "    V = dxd numpy matrix\n",
    "    z = dxN numpy matrix\n",
    "    S = dxd numpy matrix\n",
    "    u = 1 numpy matrix\n",
    "    r = 1 numpy matrix\n",
    "    f = 1 numpy matrix\n",
    "    logllfunc = function which calculates logll\n",
    "                (uses self._log_ll by default)\n",
    "    gradfunc = function which calculated grad of logll\n",
    "                (uses self._grad_ll_v by default)\n",
    "\n",
    "    Outputs:\n",
    "    -log_ll = 1x1 scalar\n",
    "    -Gvec = dxd numpy matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Unflatten V into a matrix\n",
    "    d = S[0].shape[0]\n",
    "    N = len(S)\n",
    "    \n",
    "    Gvec = np.zeros((N, 3))\n",
    "    log_ll = np.zeros(N)\n",
    "\n",
    "    for i in prange(N):\n",
    "\n",
    "        Si = S[i]\n",
    "        zi = z[i, :]\n",
    "        ui = u[i]\n",
    "        ri = r[i]\n",
    "\n",
    "        # Si = N * Si\n",
    "\n",
    "        log_ll[i] = (1/ui) * _log_ll(V, zi, Si, ri, N)\n",
    "        Gvec[i, :] = (1/ui) * _grad_ll_v(V, zi, Si, ri, N)  #_num_grad_V\n",
    "\n",
    "    return -log_ll.sum() , -Gvec.sum(axis = 0)\n",
    "\n",
    "def neglike_wrapper(V, z, S, u, r, f):\n",
    "    \n",
    "    '''\n",
    "    Wrapper for neg_logll_grad to convert V from an\n",
    "    array of individual parameters to a symmetric\n",
    "    matrix and solve for the negative log likelihood\n",
    "    '''\n",
    "\n",
    "    d = S[0].shape[0]\n",
    "    N = S.shape[0]\n",
    "    \n",
    "    normalizer = 2 * f  * (1 - f) if f is not None else np.ones(N)\n",
    "    S = normalize_S(S, normalizer)\n",
    "    \n",
    "    logll, Gvec = neg_logll_grad(V, \n",
    "                               z, S, \n",
    "                               u, r)\n",
    "    \n",
    "    print(f\"Logll : {logll}\")\n",
    "    print(f\"V : {V}\")\n",
    "    \n",
    "    return logll, Gvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32300.330467425734, array([104.25864396, -76.77297078,  24.49580842]))"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "neg_logll_grad(Vmat2V(V/N, N), z, S, r, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logll : 32300.330467425734\nV : [0.5 0.5 0.5]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32300.330467425734, array([104.25864396, -76.77297078,  24.49580842]))"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "neglike_wrapper(Vmat2V(V/N, N), z, S, r, r, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logll : 33351.59910626821\n",
      "V : [1. 1. 1.]\n",
      "Logll : 32335.948538664936\n",
      "V : [0.59175198 0.59175198 0.18350315]\n",
      "Logll : 32311.79959838797\n",
      "V : [0.54369924 0.6137565  0.29436543]\n",
      "Logll : 32298.683663287156\n",
      "V : [0.44622699 0.56091267 0.42845312]\n",
      "Logll : 32296.727459379115\n",
      "V : [0.47353369 0.53963911 0.48372808]\n",
      "Logll : 32296.483385116346\n",
      "V : [0.46400225 0.54243472 0.47605599]\n",
      "Logll : 32296.4829140356\n",
      "V : [0.46342091 0.54254395 0.47634488]\n",
      "Logll : 32296.482905947763\n",
      "V : [0.46338287 0.54258003 0.47642612]\n",
      "Logll : 32296.482905854777\n",
      "V : [0.46338225 0.54258368 0.47643514]\n",
      "Logll : 32296.482905854755\n",
      "V : [0.4633823  0.54258363 0.47643523]\n"
     ]
    }
   ],
   "source": [
    "# solving\n",
    "result = minimize(\n",
    "            neglike_wrapper, \n",
    "            np.ones(3),\n",
    "            jac = True,\n",
    "            args = (z, S, r, r, None),\n",
    "            bounds = [(1e-6, None), (1e-6, None), (-1, 1)],\n",
    "            method = 'L-BFGS-B',\n",
    "            options = {'ftol' : 1e-20}\n",
    "        )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'v1': 0.46338229858454855, 'v2': 0.5425836332925408, 'r': 0.4764352254823297}\n"
     ]
    }
   ],
   "source": [
    "estimated_parameters = dict(\n",
    "    v1 = result.x[0],\n",
    "    v2 = result.x[1],\n",
    "    r = result.x[2]\n",
    ")\n",
    "\n",
    "print(estimated_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}